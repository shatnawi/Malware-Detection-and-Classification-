from __future__ import division, unicode_literals

import collections
import hashlib
import logging
import numbers
import re
import sys
from itertools import groupby
import datetime
import time
import numpy as np

if sys.version_info[0] >= 3:
    basestring = str
    unicode = str
    long = int


    def int_to_bytes(n, length):
        return n.to_bytes(length, 'big')


    def bytes_to_int(b):
        return int.from_bytes(b, 'big')
else:
    range = xrange


    def int_to_bytes(n, length):
        return '{:0{}x}'.format(n, length * 2).decode('hex')


    def bytes_to_int(b):
        return int(b.encode('hex'), 16)


def _hashfunc(x):
    return hashlib.md5(x).digest()


class Simhash(object):
    large_weight_cutoff = 50
    batch_size = 200

    def __init__(
            self, value, f=64, reg=r'[\w\u4e00-\u9fcc]+', hashfunc=_hashfunc, log=None, weights=[], ngram="word"
    ):
        if f % 8:
            raise ValueError('f must be a multiple of 8')

        self.orgstr = value
        self.f = f
        self.f_bytes = f // 8
        self.reg = reg
        self.value = None
        self.hashfunc = hashfunc
        self.hashfunc_returns_int = isinstance(hashfunc(b"test"), numbers.Integral)
        self.weights = weights
        self.ngram = ngram

        if log is None:
            self.log = logging.getLogger("simhash")
        else:
            self.log = log

        if isinstance(value, Simhash):
            self.value = value.value
        elif isinstance(value, basestring):
            self.build_by_text()
        elif isinstance(value, collections.Iterable):
            self.build_by_features(value)
        elif isinstance(value, numbers.Integral):
            self.value = value
        else:
            raise Exception('Bad parameter with type {}'.format(type(value)))

    def __eq__(self, other):
        return self.value == other.value

    def _slide(self, content, width):
        return [content[i:i + width] for i in range(max(len(content) - width + 1, 1))]

    def _tokenize(self, content):
        # words = content.split()
        # newWords = []
        # for word in words:
        #     newWords.append(word.replace(',', '').replace('.', ''))

        # print(','.join(newWords))

        ans = self.get_character_ngrams(2) if self.ngram == 'character' else self.get_word_ngrams(1)
        return ans

    def get_word_ngrams(self, width):
        content = self.orgstr.split()
        ans = self._slide(content, width)
        return [' '.join(str) for str in ans]

    def get_character_ngrams(self, width):
        content = self.orgstr.lower()
        ans = self._slide(content, width)
        return ans

    def build_by_text(self):
        features = self._tokenize(self.orgstr)
        features = {k: sum(1 for _ in g) for k, g in groupby(sorted(features))}

        # check weight
        for feature in features:
            for weight in self.weights:
                if feature in weight[0]:
                    features[feature] *= weight[1]
                    break
        return self.build_by_features(features)

    def build_by_features(self, features):
        sums = []
        batch = []
        count = 0
        w = 1
        truncate_mask = 2 ** self.f - 1
        if isinstance(features, dict):
            features = features.items()

        for f in features:
            skip_batch = False
            if not isinstance(f, basestring):
                f, w = f
                skip_batch = w > self.large_weight_cutoff or not isinstance(w, int)

            count += w
            if self.hashfunc_returns_int:
                h = int_to_bytes(self.hashfunc(f.encode('utf-8')) & truncate_mask, self.f_bytes)
            else:
                h = self.hashfunc(f.encode('utf-8'))[-self.f_bytes:]

            if skip_batch:
                sums.append(self._bitarray_from_bytes(h) * w)
            else:
                batch.append(h * w)
                if len(batch) >= self.batch_size:
                    sums.append(self._sum_hashes(batch))
                    batch = []

            if len(sums) >= self.batch_size:
                sums = [np.sum(sums, 0)]

        if batch:
            sums.append(self._sum_hashes(batch))

        combined_sums = np.sum(sums, 0)
        self.value = bytes_to_int(np.packbits(combined_sums > count / 2).tobytes())

    def _sum_hashes(self, digests):
        bitarray = self._bitarray_from_bytes(b''.join(digests))
        rows = np.reshape(bitarray, (-1, self.f))
        return np.sum(rows, 0)

    @staticmethod
    def _bitarray_from_bytes(b):
        return np.unpackbits(np.frombuffer(b, dtype='>B'))

    def distance(self, another):
        assert self.f == another.f
        x = (self.value ^ another.value) & ((1 << self.f) - 1)
        ans = 0
        while x:
            ans += 1
            x &= x - 1
        return ans


class SimhashIndex(object):

    def __init__(self, objs, f=64, k=2, log=None):
        self.k = k
        self.f = f
        count = len(objs)

        if log is None:
            self.log = logging.getLogger("simhash")
        else:
            self.log = log

        self.log.info('Initializing %s data.', count)

        self.bucket = collections.defaultdict(set)

        for i, q in enumerate(objs):
            if i % 10000 == 0 or i == count - 1:
                self.log.info('%s/%s', i + 1, count)

            self.add(*q)

    def get_near_dups(self, simhash):
        assert simhash.f == self.f

        ans = set()

        for key in self.get_keys(simhash):
            dups = self.bucket[key]
            self.log.debug('key:%s', key)
            if len(dups) > 200:
                self.log.warning('Big bucket found. key:%s, len:%s', key, len(dups))

            for dup in dups:
                sim2, obj_id = dup.split(',', 1)
                sim2 = Simhash(long(sim2, 16), self.f)

                d = simhash.distance(sim2)
                if d <= self.k:
                    ans.add(obj_id)
        return list(ans)

    def add(self, obj_id, simhash):
        assert simhash.f == self.f

        for key in self.get_keys(simhash):
            v = '%x,%s' % (simhash.value, obj_id)
            self.bucket[key].add(v)

    def delete(self, obj_id, simhash):
        assert simhash.f == self.f

        for key in self.get_keys(simhash):
            v = '%x,%s' % (simhash.value, obj_id)
            if v in self.bucket[key]:
                self.bucket[key].remove(v)

    @property
    def offsets(self):
        return [self.f // (self.k + 1) * i for i in range(self.k + 1)]

    def get_keys(self, simhash):
        for i, offset in enumerate(self.offsets):
            if i == (len(self.offsets) - 1):
                m = 2 ** (self.f - offset) - 1
            else:
                m = 2 ** (self.offsets[i + 1] - offset) - 1
            c = simhash.value >> offset & m
            yield '%x:%x' % (c, i)

    def bucket_size(self):
        return len(self.bucket)


#########################################################################
import csv
#from Simhash import Simhash
from PIL import Image, ImageDraw
import hashlib
import os
start = datetime.datetime.now()
# read data.csv for input
file = open('/Users/wafaakahla/Desktop/code/File/Datasets_after_Filtering2/Static_filtering.csv')
csvreader = csv.reader(file)

# you can save string list into vector
vectors = []
# you can customize special weights
weights = [('',1)]
# make weights string lowercases
weights = [(weight[0].lower(), weight[1]) for weight in weights]

# Choose one of these hash_func:
# hashlib.sha1(x).digest()
# hashlib.sha224(x).digest()
# hashlib.sha256(x).digest()
# hashlib.sha384(x).digest()
# you can input ngram parameter (character or word)

totalbits = 512 # you can change this value by changing sha algorithm
counter = {}
# read each line from csv file and calc Symhash for each string
for row in csvreader:
    title = row[0]
    # make a symhash object. you can change the parameter, so the hash method, weight or ngram
    sym = Simhash(row[1], totalbits, hashfunc=lambda x: hashlib.sha512(x).digest(), weights=weights, ngram="word")
    counter[title] =1

    vectors.append((title, sym))

# write result to a output.csv
csvwriter = csv.writer(open('/Users/wafaakahla/Desktop/code/File/Datasets_after_Simhash/1word/Static/SHA_512/sim_S_512.csv', 'w'))

for vec in vectors:
    binary = '{0:b}'.format(vec[1].value)
    binary = binary.zfill(totalbits)
    # print output to console in binary format
    #print('Simhash code binary({0}) : {1}'.format(binary, vec[0]))

    result = []

    # make a result data for writing
    for char in binary:
        result.append(char)
    result.append(vec[0])

    csvwriter.writerow(result)

end= datetime.datetime.now()
elapsed= end-start
print ('Time: ', elapsed)

######################################################################################################################

import csv
#from Simhash import Simhash
from PIL import Image, ImageDraw
import hashlib
import os
start = datetime.datetime.now()
# read data.csv for input
file = open('/Users/wafaakahla/Desktop/code/File/Datasets_after_Filtering2/Dynamic_filtering.csv')
csvreader = csv.reader(file)

# you can save string list into vector
vectors = []
# you can customize special weights
weights = [('',1), ('',1)]
# make weights string lowercases
weights = [(weight[0].lower(), weight[1]) for weight in weights]

# Choose one of these hash_func:
# hashlib.sha1(x).digest()
# hashlib.sha224(x).digest()
# hashlib.sha256(x).digest()
# hashlib.sha384(x).digest()
# you can input ngram parameter (character or word)

totalbits = 512 # you can change this value by changing sha algorithm
counter = {}
# read each line from csv file and calc Symhash for each string
for row in csvreader:
    title = row[0]
    # make a symhash object. you can change the parameter, so the hash method, weight or ngram
    sym = Simhash(row[1], totalbits, hashfunc=lambda x: hashlib.sha512(x).digest(), weights=weights, ngram="word")
    counter[title] =1

    vectors.append((title, sym))

# write result to a output.csv
csvwriter = csv.writer(open('/Users/wafaakahla/Desktop/code/File/Datasets_after_Simhash/1word/Dynamic/SHA_512/sim_D_512.csv', 'w'))

for vec in vectors:
    binary = '{0:b}'.format(vec[1].value)
    binary = binary.zfill(totalbits)
    # print output to console in binary format
    #print('Simhash code binary({0}) : {1}'.format(binary, vec[0]))

    result = []

    # make a result data for writing
    for char in binary:
        result.append(char)
    result.append(vec[0])

    csvwriter.writerow(result)

end= datetime.datetime.now()
elapsed= end-start
print ('Time: ', elapsed)

###################################################################################

import csv

with open("/Users/wafaakahla/Desktop/code/File/Datasets_after_Simhash/1word/Static/SHA_512/sim_S_512.csv") as i1, open(
        "/Users/wafaakahla/Desktop/code/File/Datasets_after_Simhash/1word/Dynamic/SHA_512/sim_D_512.csv") as i2, open("/Users/wafaakahla/Desktop/code/File/Datasets_after_Simhash/1word/Hybrid/SHA_512/test.csv",
                                                                      "w") as out:
    writer = csv.writer(out)

    for set1, set2 in zip(csv.reader(i1), csv.reader(i2)):
        writer.writerow(set1[:-1] + set2)

###########################################################################
end= datetime.datetime.now()
elapsed= end-start
print ('Time: ', elapsed)